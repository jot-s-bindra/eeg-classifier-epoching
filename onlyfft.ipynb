{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file cleaned_eeg_data_left2.fif...\n",
      "Isotrak not found\n",
      "    Range : 0 ... 10527 =      0.000 ...    82.242 secs\n",
      "Ready.\n",
      "Reading 0 ... 10527  =      0.000 ...    82.242 secs...\n",
      "Opening raw data file cleaned_eeg_data_right.fif...\n",
      "Isotrak not found\n",
      "    Range : 0 ... 16255 =      0.000 ...   126.992 secs\n",
      "Ready.\n",
      "Reading 0 ... 16255  =      0.000 ...   126.992 secs...\n",
      "Opening raw data file cleaned_eeg_data_up.fif...\n",
      "Isotrak not found\n",
      "    Range : 0 ... 10136 =      0.000 ...    79.188 secs\n",
      "Ready.\n",
      "Reading 0 ... 10136  =      0.000 ...    79.188 secs...\n",
      "Opening raw data file cleaned_eeg_data_down.fif...\n",
      "Isotrak not found\n",
      "    Range : 0 ... 18327 =      0.000 ...   143.180 secs\n",
      "Ready.\n",
      "Reading 0 ... 18327  =      0.000 ...   143.180 secs...\n",
      "Not setting metadata\n",
      "82 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 82 events and 129 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "127 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 127 events and 129 original time points ...\n",
      "1 bad epochs dropped\n",
      "Not setting metadata\n",
      "79 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 79 events and 129 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "143 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 143 events and 129 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_272636/2385749654.py:5: RuntimeWarning: This filename (cleaned_eeg_data_left2.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  left_data = mne.io.read_raw_fif('cleaned_eeg_data_left2.fif', preload=True)\n",
      "/tmp/ipykernel_272636/2385749654.py:6: RuntimeWarning: This filename (cleaned_eeg_data_right.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  right_data = mne.io.read_raw_fif('cleaned_eeg_data_right.fif', preload=True)\n",
      "/tmp/ipykernel_272636/2385749654.py:7: RuntimeWarning: This filename (cleaned_eeg_data_up.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  up_data = mne.io.read_raw_fif('cleaned_eeg_data_up.fif', preload=True)\n",
      "/tmp/ipykernel_272636/2385749654.py:8: RuntimeWarning: This filename (cleaned_eeg_data_down.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  down_data = mne.io.read_raw_fif('cleaned_eeg_data_down.fif', preload=True)\n"
     ]
    }
   ],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "from scipy.signal import welch\n",
    "\n",
    "left_data = mne.io.read_raw_fif('cleaned_eeg_data_left2.fif', preload=True)\n",
    "right_data = mne.io.read_raw_fif('cleaned_eeg_data_right.fif', preload=True)\n",
    "up_data = mne.io.read_raw_fif('cleaned_eeg_data_up.fif', preload=True)\n",
    "down_data = mne.io.read_raw_fif('cleaned_eeg_data_down.fif', preload=True)\n",
    "\n",
    "# left_data = mne.io.read_raw_fif('LEFT.fif', preload=True)\n",
    "# right_data = mne.io.read_raw_fif('RIGHT.fif', preload=True)\n",
    "# up_data = mne.io.read_raw_fif('UP.fif', preload=True)\n",
    "# down_data = mne.io.read_raw_fif('DOWN.fif', preload=True)\n",
    "\n",
    "epoch_duration = 1  \n",
    "overlap = 0.5  \n",
    "left_events = mne.make_fixed_length_events(left_data, duration=epoch_duration)\n",
    "right_events = mne.make_fixed_length_events(right_data, duration=epoch_duration)\n",
    "up_events = mne.make_fixed_length_events(up_data, duration=epoch_duration)\n",
    "down_events = mne.make_fixed_length_events(down_data, duration=epoch_duration)\n",
    "\n",
    "left_epochs = mne.Epochs(left_data, events=left_events, tmin=0, tmax=epoch_duration, baseline=None, preload=True)\n",
    "right_epochs = mne.Epochs(right_data, events=right_events, tmin=0, tmax=epoch_duration, baseline=None, preload=True)\n",
    "up_epochs = mne.Epochs(up_data, events=up_events, tmin=0, tmax=epoch_duration, baseline=None, preload=True)\n",
    "down_epochs = mne.Epochs(down_data, events=down_events, tmin=0, tmax=epoch_duration, baseline=None, preload=True)\n",
    "\n",
    "freq_bands = {'Delta': (0.5, 4),\n",
    "              'Theta': (4, 8),\n",
    "              'Alpha': (8, 13),\n",
    "              'Beta': (13, 30),#should be more prevalent during our game\n",
    "              'Gamma': (30, 40)}  \n",
    "\n",
    "# def compute_avg_band_powers(epochs):\n",
    "#     avg_band_powers = []\n",
    "#     for epoch in epochs:\n",
    "#         channel_band_powers = []\n",
    "#         for channel_data in epoch:\n",
    "#             for band in freq_bands.values():\n",
    "#                 fmin, fmax = band\n",
    "#                 freqs, psd = welch(channel_data, left_data.info['sfreq'], nperseg=left_data.info['sfreq']*epoch_duration, scaling='density')\n",
    "#                 idx_band = np.logical_and(freqs >= fmin, freqs <= fmax)\n",
    "#                 band_power = np.mean(psd[idx_band])\n",
    "#                 channel_band_powers.append(band_power)\n",
    "#         avg_band_powers.append(np.mean(channel_band_powers))\n",
    "#     return avg_band_powers\n",
    "\n",
    "# left_avg_band_powers = compute_avg_band_powers(left_epochs)\n",
    "# right_avg_band_powers = compute_avg_band_powers(right_epochs)\n",
    "# up_avg_band_powers = compute_avg_band_powers(up_epochs)\n",
    "# down_avg_band_powers = compute_avg_band_powers(down_epochs)\n",
    "\n",
    "# labels = np.concatenate((\n",
    "#     np.zeros(len(left_avg_band_powers)),        # Left category labeled as 0\n",
    "#     np.ones(len(right_avg_band_powers)),       # Right category labeled as 1\n",
    "#     np.full(len(up_avg_band_powers), 2),       # Up category labeled as 2\n",
    "#     np.full(len(down_avg_band_powers), 3)      # Down category labeled as 3\n",
    "# ))\n",
    "\n",
    "# all_avg_band_powers = (\n",
    "#     left_avg_band_powers + \n",
    "#     right_avg_band_powers +\n",
    "#     up_avg_band_powers +\n",
    "#     down_avg_band_powers\n",
    "# )\n",
    "\n",
    "# X = np.array(all_avg_band_powers)\n",
    "def compute_avg_band_amplitudes(epochs):\n",
    "    avg_band_amplitudes = []\n",
    "    for epoch in epochs:\n",
    "        channel_band_amplitudes = []\n",
    "        for channel_data in epoch:\n",
    "            for band in freq_bands.values():\n",
    "                fmin, fmax = band\n",
    "                sp = np.fft.fft(channel_data)\n",
    "                freq = np.fft.fftfreq(len(channel_data), d=1/left_data.info['sfreq'])\n",
    "                freq = freq[1:int(np.ceil(len(channel_data) / 4))]  \n",
    "                sp = sp[1:int(np.ceil(len(channel_data) / 4))]\n",
    "                sp = np.sqrt(sp.real**2 + sp.imag**2)\n",
    "                band_indices = np.logical_and(freq >= fmin, freq <= fmax)\n",
    "                band_amplitude = np.mean(sp[band_indices])\n",
    "                channel_band_amplitudes.append(band_amplitude)\n",
    "        avg_band_amplitudes.append(np.mean(channel_band_amplitudes))\n",
    "    return avg_band_amplitudes\n",
    "\n",
    "left_avg_band_amplitudes = compute_avg_band_amplitudes(left_epochs)\n",
    "right_avg_band_amplitudes = compute_avg_band_amplitudes(right_epochs)\n",
    "up_avg_band_amplitudes = compute_avg_band_amplitudes(up_epochs)\n",
    "down_avg_band_amplitudes = compute_avg_band_amplitudes(down_epochs)\n",
    "all_avg_band_amplitudes = left_avg_band_amplitudes + up_avg_band_amplitudes+down_avg_band_amplitudes+right_avg_band_amplitudes\n",
    "\n",
    "X = np.array(all_avg_band_amplitudes)\n",
    "labels = np.concatenate((\n",
    "    np.zeros(len(left_avg_band_amplitudes)),        # Left category labeled as 0\n",
    "    np.ones(len(right_avg_band_amplitudes)),       # Right category labeled as 1\n",
    "    np.full(len(up_avg_band_amplitudes), 2),       # Up category labeled as 2\n",
    "    np.full(len(down_avg_band_amplitudes), 3)      # Down category labeled as 3\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of epochs for left data: 82\n",
      "Number of epochs for right data: 126\n",
      "Number of epochs for up data: 79\n",
      "Number of epochs for down data: 143\n"
     ]
    }
   ],
   "source": [
    "num_left_epochs = len(left_epochs)\n",
    "num_right_epochs = len(right_epochs)\n",
    "\n",
    "print(f\"Number of epochs for left data: {num_left_epochs}\")\n",
    "print(f\"Number of epochs for right data: {num_right_epochs}\")\n",
    "\n",
    "num_up_epochs = len(up_epochs)\n",
    "num_down_epochs = len(down_epochs)\n",
    "\n",
    "print(f\"Number of epochs for up data: {num_up_epochs}\")\n",
    "print(f\"Number of epochs for down data: {num_down_epochs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Predicted Label - 3.0, Max Class Probability - 0.363979582484867\n",
      "Epoch 2: Predicted Label - 3.0, Max Class Probability - 0.3733364709397264\n",
      "Epoch 3: Predicted Label - 3.0, Max Class Probability - 0.33493213097056734\n",
      "Epoch 4: Predicted Label - 3.0, Max Class Probability - 0.3601286868774951\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "import numpy as np\n",
    "\n",
    "def exclude_one_epoch_for_testing(epochs):\n",
    "    testing_epochs = []\n",
    "    rest_epochs = []\n",
    "\n",
    "    for idx, epoch in enumerate(epochs):\n",
    "        if idx == 5:  \n",
    "            testing_epochs.append(epoch)\n",
    "        else:\n",
    "            rest_epochs.append(epoch)\n",
    "\n",
    "    return testing_epochs, rest_epochs\n",
    "\n",
    "left_testing, left_training = exclude_one_epoch_for_testing(left_epochs)\n",
    "right_testing, right_training = exclude_one_epoch_for_testing(right_epochs)\n",
    "up_testing, up_training = exclude_one_epoch_for_testing(up_epochs)\n",
    "down_testing, down_training = exclude_one_epoch_for_testing(down_epochs)\n",
    "\n",
    "testing_epochs = left_testing + right_testing + up_testing + down_testing\n",
    "training_epochs = left_training + right_training + up_training + down_training\n",
    "\n",
    "X_train = np.array(compute_avg_band_amplitudes(training_epochs))\n",
    "\n",
    "labels_train = np.concatenate((\n",
    "    np.zeros(len(left_training)),        # Left category labeled as 0\n",
    "    np.ones(len(right_training)),       # Right category labeled as 1\n",
    "    np.full(len(up_training), 2),       # Up category labeled as 2\n",
    "    np.full(len(down_training), 3)      # Down category labeled as 3\n",
    "))\n",
    "\n",
    "X_test = np.array(compute_avg_band_amplitudes(testing_epochs))\n",
    "\n",
    "labels_test = np.concatenate((\n",
    "    np.zeros(len(left_testing)),        # Left category labeled as 0\n",
    "    np.ones(len(right_testing)),       # Right category labeled as 1\n",
    "    np.full(len(up_testing), 2),       # Up category labeled as 2\n",
    "    np.full(len(down_testing), 3)      # Down category labeled as 3\n",
    "))\n",
    "\n",
    "X_train = X_train.reshape(-1, 1)  \n",
    "\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "lda.fit(X_train, labels_train)\n",
    "\n",
    "X_test = X_test.reshape(-1, 1)  \n",
    "\n",
    "predicted_labels = lda.predict(X_test)\n",
    "\n",
    "prediction_probabilities = lda.predict_proba(X_test)\n",
    "max_class_probabilities = prediction_probabilities.max(axis=1)\n",
    "\n",
    "for i, (predicted_label, max_class_prob) in enumerate(zip(predicted_labels, max_class_probabilities)):\n",
    "    print(f\"Epoch {i + 1}: Predicted Label - {predicted_label}, Max Class Probability - {max_class_prob}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 39.53%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.70      0.29      0.41        24\n",
      "         1.0       0.62      0.19      0.29        26\n",
      "         2.0       0.00      0.00      0.00        12\n",
      "         3.0       0.32      0.92      0.48        24\n",
      "\n",
      "    accuracy                           0.40        86\n",
      "   macro avg       0.41      0.35      0.30        86\n",
      "weighted avg       0.47      0.40      0.34        86\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/outbreakkp/anaconda3/envs/nlp/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/outbreakkp/anaconda3/envs/nlp/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/outbreakkp/anaconda3/envs/nlp/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, random_state=42)\n",
    "X_train = X_train.reshape(X_train.shape[0], -1)\n",
    "\n",
    "lda_classifier = LinearDiscriminantAnalysis()\n",
    "lda_classifier.fit(X_train, y_train)\n",
    "\n",
    "X_test = X_test.reshape(X_test.shape[0], -1)\n",
    "\n",
    "predictions = lda_classifier.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "report = classification_report(y_test, predictions)\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lda_model.joblib']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump\n",
    "model_filename = 'lda_model.joblib'  \n",
    "dump(lda_classifier, model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_data = mne.io.read_raw_fif('cleaned_eeg_data_right.fif', preload=True)\n",
    "\n",
    "# new_events = mne.make_fixed_length_events(new_data, duration=epoch_duration)\n",
    "\n",
    "# new_epochs = mne.Epochs(new_data, events=new_events, tmin=0, tmax=epoch_duration, baseline=None, preload=True)\n",
    "\n",
    "# new_avg_band_amplitudes = compute_avg_band_amplitudes(new_epochs)\n",
    "\n",
    "# X_new = np.array(new_avg_band_amplitudes)\n",
    "# X_new = X_new.reshape(X_new.shape[0], -1)\n",
    "\n",
    "# predictions_new = lda_classifier.predict(X_new)\n",
    "# predictions_probabilities = lda_classifier.predict_proba(X_new)\n",
    "# print(\"Probabilities for each class:\")\n",
    "# for i, probs in enumerate(predictions_probabilities):\n",
    "#     print(f\"Sample {i+1}: Left: {probs[0]:.2f}, Up: {probs[1]:.2f}, Down: {probs[2]:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
